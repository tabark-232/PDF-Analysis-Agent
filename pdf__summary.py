# -*- coding: utf-8 -*-
"""PDF_ Summary.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-qpWN-P684TKhriu9wW4BF5SDQcWBujv
"""

!pip install gradio pdfplumber transformers google-cloud-translate

import gradio as gr
import pdfplumber
from transformers import pipeline
from google.cloud import translate_v2 as translate
import traceback

summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
qa_pipeline = pipeline("question-answering", model="deepset/roberta-base-squad2")

def read_pdf(file_path):
    text = ""
    try:
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text
    except Exception as e:
        print("ğŸš¨ Error reading PDF:", e)
    return text

def summarize_large_text(text, chunk_size=1000):
    chunks = [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]
    summary = ""
    for chunk in chunks:
        try:
            summarized = summarizer(chunk, max_length=300, min_length=50, do_sample=False)
            summary += summarized[0]['summary_text'] + "\n"
        except Exception as e:
            print("ğŸš¨ Error during summarization:", e)
    return summary.strip()

def translate_text(text, src_lang="en", dest_lang="ar"):
    try:
        translate_client = translate.Client()
        result = translate_client.translate(text, source_language=src_lang, target_language=dest_lang)
        return result["translatedText"]
    except Exception as e:
        print("ğŸš¨ Translation error:", e)
        return "âš ï¸ Translation failed."

def detect_language(text):
    if any(char in text for char in "Ø§Ø¨ØªØ«Ø¬Ø­Ø®Ø¯Ø°Ø±Ø²Ø³Ø´ØµØ¶Ø·Ø¸Ø¹ØºÙÙ‚ÙƒÙ„Ù…Ù†Ù‡ÙˆÙŠ"):
        return "ar"
    return "en"

context_text = ""

def upload_and_process(file):
    global context_text
    text = read_pdf(file.name)
    if not text:
        return "âš ï¸ The file is empty or unsupported."

    lang = detect_language(text[:300])
    context_text = text
    if lang == "ar":
        translated_to_en = translate_text(text, src_lang="ar", dest_lang="en")
        summary_en = summarize_large_text(translated_to_en)
        summary_ar = translate_text(summary_en, src_lang="en", dest_lang="ar")
    else:
        summary_en = summarize_large_text(text)
        summary_ar = translate_text(summary_en, src_lang="en", dest_lang="ar")

    return f"âœ… File processed successfully.\n\nğŸ“˜ Summary (EN):\n{summary_en}\n\nğŸ“™ Summary (AR):\n{summary_ar}"

def chat_interface(message, history):
    global context_text
    if not context_text:
        return "âš ï¸ Please upload a PDF file first."

    try:
        lang = detect_language(message)
        q_en = message
        context_en = context_text

        if lang == "ar":
            q_en = translate_text(message, src_lang="ar", dest_lang="en")
            context_en = translate_text(context_text[:3000], src_lang="ar", dest_lang="en")

        result = qa_pipeline(question=q_en, context=context_en)
        answer_en = result["answer"]

        if lang == "ar":
            answer_ar = translate_text(answer_en, src_lang="en", dest_lang="ar")
            return answer_ar
        else:
            return answer_en

    except Exception as e:
        print("ğŸš¨ Chat error:", e)
        return "âš ï¸ Could not generate a suitable answer."

with gr.Blocks() as demo:
    gr.Markdown("## ğŸ¤– Interactive PDF Summary & Q&A Assistant (with Arabic Support)")

    with gr.Row():
        file_input = gr.File(label="ğŸ“ Upload PDF", file_types=[".pdf"])
        upload_output = gr.Textbox(label="ğŸ“„ Summary", lines=12)

    file_input.change(fn=upload_and_process, inputs=file_input, outputs=upload_output)

    gr.ChatInterface(
        fn=chat_interface,
        chatbot=gr.Chatbot(height=400),
        title="ğŸ’¬ Ask about the file content",
        description="Type your question in Arabic or English"
    )

demo.launch()